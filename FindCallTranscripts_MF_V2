import tkinter as tk
from tkinter import ttk, messagebox
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
from bs4 import BeautifulSoup
from docx import Document
from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementClickInterceptedException
import threading
import queue


def search_keyword(keyword_queue):
    # 获取用户输入的关键词，并转换为小写
    keyword = keyword_entry.get().lower()
    keyword_low = keyword

    # 初始化Word文档
    document = Document()
    document.add_heading('Earnings Call Transcripts', level=1)

    # 初始化Selenium WebDriver
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")  # 无头模式，后台运行
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    # 访问目标网站
    url = "https://www.fool.com/earnings-call-transcripts/"
    driver.get(url)

    # 等待页面加载
    time.sleep(10)

    # 最大点击次数
    max_clicks = 15
    clicks = 0
    found = False

    while clicks < max_clicks:
        # 搜索关键词并获取链接
        results = driver.find_elements(By.XPATH, f"//h5[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', "
                                                 f"'abcdefghijklmnopqrstuvwxyz'), '{keyword}')]/..")
        time.sleep(5)
        # keyword_queue.put(f"第{clicks + 1}次查找中...保持耐心bro")
        progress_var.set(clicks / max_clicks * 100)
        root.update_idletasks()
        if results:
            for result in results:
                title = result.find_element(By.TAG_NAME, "h5").text
                full_link = result.get_attribute("href")
                keyword_queue.put(f"找到内容: {title} \n 正在解析...")

                # 访问链接
                driver.get(full_link)
                time.sleep(5)

                # 获取页面内容
                page_source = driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')

                # 提取 <div class="article-body"> 中的内容
                content_div = soup.find('div', class_='article-body')
                if content_div:
                    paragraphs = content_div.find_all('p')
                    if paragraphs:
                        # 将内容添加到Word文档中
                        document.add_heading(title, level=2)  # 添加标题
                        for p in paragraphs:
                            p_text = p.get_text(strip=True)
                            if p_text:  # 确保非空
                                document.add_paragraph(p_text)  # 每个 <p> 标签作为一个段落
                        document.add_paragraph()  # 添加空行分隔内容

                # 返回主页面
                driver.get(url)
                time.sleep(5)
            found = True
            break
        else:
            # 找不到关键词时点击 "Load More" 按钮
            try:
                load_more_button = WebDriverWait(driver, 20).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, '.load-more-button'))
                )
                # 尝试多次滚动页面以确保按钮在视口内
                for _ in range(3):
                    # 滚动到页面底部
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

                    # 等待页面滚动完成
                    time.sleep(2)

                    # 向上滚动800个像素
                    driver.execute_script("window.scrollBy(0, -800);")
                    time.sleep(3)
                    if load_more_button.is_displayed() and load_more_button.is_enabled():
                        break
                try:
                    driver.execute_script("arguments[0].click();", load_more_button)  # 使用JavaScript点击
                except ElementClickInterceptedException:
                    driver.execute_script("window.scrollBy(0, -100);")
                    time.sleep(1)
                    driver.execute_script("arguments[0].click();", load_more_button)
                time.sleep(5)
                clicks += 1
            except (NoSuchElementException, TimeoutException):
                break

    # 如果未找到匹配信息，提示用户
    if not found:
        keyword_queue.put("未找到匹配内容，请稍后再试。")
    else:
        keyword_queue.put(f"内容已保存至 {keyword}_earnings_call_transcripts.docx")

    time.sleep(5)

    # 保存Word文档
    document.save(f'{keyword_low}_earnings_call_transcripts.docx')

    # 关闭浏览器
    driver.quit()
    progress_var.set(0)

    # 重新启用搜索按钮并更新状态标签
    keyword_queue.put("完成")
    search_button.config(state=tk.NORMAL)


def update_status(keyword_queue):
    try:
        while True:
            message = keyword_queue.get_nowait()
            status_label.config(text=message)
            root.update_idletasks()
            if message == "完成":
                break
    except queue.Empty:
        root.after(100, update_status, keyword_queue)


def start_search():
    search_button.config(state=tk.DISABLED)
    status_label.config(text="程序启动并运行中，请稍候...")
    root.update_idletasks()
    keyword_queue = queue.Queue()
    threading.Thread(target=search_keyword, args=(keyword_queue,)).start()
    root.after(100, update_status, keyword_queue)


# 创建Tkinter界面
root = tk.Tk()
root.title("Earnings Call Transcript Scraper")

# 输入关键词标签和输入框
keyword_label = tk.Label(root, text="请输入关键词(公司英文全名或股票代码)：")
keyword_label.pack(pady=10)
keyword_entry = tk.Entry(root, width=50)
keyword_entry.pack(pady=10)

# 搜索按钮
search_button = tk.Button(root, text="搜索", command=start_search)
search_button.pack(pady=10)

# 进度条
progress_var = tk.DoubleVar()
progress_bar = ttk.Progressbar(root, variable=progress_var, maximum=100)
progress_bar.pack(pady=20, fill=tk.X)

# 状态标签
status_label = tk.Label(root, text="")
status_label.pack(pady=10)

# 启动Tkinter主循环
root.mainloop()
